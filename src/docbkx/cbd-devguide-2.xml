<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book [
<!-- Some useful entities borrowed from HTML -->
<!ENTITY ndash  "&#x2013;">
<!ENTITY mdash  "&#x2014;">
<!ENTITY hellip "&#x2026;">

<!-- Useful for describing APIs -->
<!ENTITY GET    '<command xmlns="http://docbook.org/ns/docbook">GET</command>'>
<!ENTITY PUT    '<command xmlns="http://docbook.org/ns/docbook">PUT</command>'>
<!ENTITY POST   '<command xmlns="http://docbook.org/ns/docbook">POST</command>'>
<!ENTITY DELETE '<command xmlns="http://docbook.org/ns/docbook">DELETE</command>'>
<!ENTITY PRODNAME "Cloud Big Data">

<!-- changing authentication endpoints; define entities for US & UK rather than maintaining in text -->
<!ENTITY ENDPOINT-US "https://auth.api.rackspacecloud.com/v2.0/">
<!ENTITY ENDPOINT-UK "https://lon.identity.api.rackspacecloud.com/v1.1/">

<!ENTITY CHECK  '<inlinemediaobject xmlns="http://docbook.org/ns/docbook">
<imageobject>
<imagedata fileref="img/Check_mark_23x20_02.svg"
format="SVG" scale="60"/>
</imageobject>
</inlinemediaobject>'>

<!ENTITY ARROW  '<inlinemediaobject xmlns="http://docbook.org/ns/docbook">
<imageobject>
<imagedata fileref="img/Arrow_east.svg"
format="SVG" scale="60"/>
</imageobject>
</inlinemediaobject>'>

]>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:svg="http://www.w3.org/2000/svg"
  xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:html="http://www.w3.org/1999/xhtml"
  xmlns:wadl="http://wadl.dev.java.net/2009/02" version="5.0-extension RackBook-2.0"
  xml:id="cbd-devguide">
  <!-- <?rax 
    title.font.size="30px" 
    subtitle.font.size="20px"         
    canonical.url.base="http://docs-internal.rackspace.com/cbd/api/v1.0/cbd-devguide-2/content"
    status.bar.text=""?>
  <title>Rackspace &PRODNAME; Developer Guide</title>
  <titleabbrev>&PRODNAME; Developer Guide</titleabbrev>
-->
  <?rax title.font.size="35px" subtitle.font.size="20px"
  status.bar.text="DRAFT"?>
  <title>Rackspace Cloud Big Data Developer Guide, v2</title>
  <titleabbrev>Cloud Big Data Developer Guide, v2</titleabbrev>
  <info>
    <author>
      <personname>
        <firstname/>
        <surname> </surname></personname>
      <affiliation>
        <orgname>Rackspace Cloud</orgname>
      </affiliation>
    </author>
    <copyright>
      <year>2014</year>
      <holder>Rackspace US, Inc.</holder>
    </copyright>
    <releaseinfo>API v2.0</releaseinfo>
    <productname>Rackspace &PRODNAME;</productname>
    <pubdate/>
    <legalnotice role="rs-api">
      <annotation>
        <remark>Copyright details are filled in by the doc build process.</remark>
      </annotation>
    </legalnotice>
    <abstract>
      <para>This guide is intended for software developers interested in developing applications
        using the Rackspace &PRODNAME; Application Programming Interface (<abbrev>API</abbrev>). </para>
    </abstract>
    <revhistory xmlns:svg="http://www.w3.org/2000/svg" xmlns:m="http://www.w3.org/1998/Math/MathML"
      xmlns:html="http://www.w3.org/1999/xhtml">
      <revision>
        <date>2014-06-10</date>
        <revdescription>
          <para>Initial Release of the LAVA 2 API.</para>
        </revdescription>
      </revision>
    </revhistory>
    <raxm:metadata xmlns:raxm="http://docs.rackspace.com/api/metadata">
      <raxm:displayname>API Developer Guide, v2</raxm:displayname>
      <raxm:product version="v1.0">cbd</raxm:product>
      <raxm:priority>15</raxm:priority>
    </raxm:metadata>
  </info>
  <chapter xml:id="overview">
    <title>Overview</title>
    <para>Rackspace &PRODNAME; is an on-demand Apache Hadoop service on the Rackspace open cloud.
      The service supports a RESTful API and alleviates the pain associated with deploying,
      managing, and scaling Hadoop clusters. </para>
    <para>Cloud Big Data is just as flexible and feature-rich as Hadoop. With Cloud Big Data, you
      benefit from on-demand servers, utility-based pricing, and access to the full set of Hadoop
      features and APIs. However, you do not have to worry about provisioning, growing, or
      maintaining your Hadoop infrastructure. The Cloud Big Data service uses an environment that is
      specifically optimized for Hadoop, which ensures that your jobs run efficiently and reliably.
      Note that you are still responsible for developing, troubleshooting, and deploying your
      applications. </para>
    <para>The primary use cases for &PRODNAME; are as follows: </para>
    <itemizedlist>
      <listitem>
        <para>Create on-demand infrastructure for applications in production where physical servers
          would be too costly and time-consuming to configure and maintain.</para>
      </listitem>
      <listitem>
        <para>Develop, test, and pilot data analysis applications.</para>
      </listitem>
    </itemizedlist>
    <para>&PRODNAME; provides the following benefits: <itemizedlist>
        <listitem>
          <para>Create or resize Hadoop clusters in minutes and pay only for what you use.</para>
        </listitem>
        <listitem>
          <para>Access the Hortonworks Data Platform (HDP), an enterprise-ready distribution that is
            100 percent Apache open source.</para>
        </listitem>
        <listitem>
          <para>Provision and manage Hadoop using an easy-to-use Control Panel and a RESTful
            API.</para>
        </listitem>
        <listitem>
          <para>Seamlessly access data in Cloud Files containers.</para>
        </listitem>
        <listitem>
          <para>Gain interoperability with any third party software tool that supports HDP.</para>
        </listitem>
        <listitem>
          <para>Fanatical Support® on a 24x7x365 basis via chat, phone or ticket.</para>
        </listitem>
      </itemizedlist>
    </para>
    <section xml:id="Intended_Audience-d1e122">
      <title>Intended audience</title>
      <para>This guide is intended to assist software developers who want to develop applications by
        using the &PRODNAME; API. It assumes the reader has a general understanding of Big Data
        concepts and is familiar with the following technology: </para>
      <itemizedlist spacing="compact">
        <listitem>
          <para>Hadoop, Apache Hadoop Distributed File System (HDFS), and MapReduce</para>
        </listitem>
        <listitem>
          <para>Hortonworks Data Platform (HDP)</para>
        </listitem>
        <listitem>
          <para>RESTful web services</para>
        </listitem>
        <listitem>
          <para>HTTP/1.1 conventions</para>
        </listitem>
        <listitem>
          <para>JSON serialization formats</para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="Document_Change_History-d1e166">
      <title>Document change history</title>
      <para>This version of the guide replaces and obsoletes all earlier versions. The most recent
        changes are described in the following table:</para>
      <?rax revhistory?>
    </section>
    <section xml:id="Early_Access-d1e122">
      <title>Prerequisites</title>
      <para>To work with the Cloud Big Data API, you must have the following
          prerequisites:<itemizedlist spacing="compact">
          <listitem>
            <para>A Rackspace Cloud account</para>
          </listitem>
          <listitem>
            <para>A Rackspace Cloud username and password, as specified during registration</para>
          </listitem>
        </itemizedlist></para>
      <para>The following OS and Hadoop distribution are supported: <itemizedlist spacing="compact">
          <listitem>
            <para>CentOS 6.5 </para>
          </listitem>
          <listitem>
            <para>HDP version 2.1 and 1.3 </para>
          </listitem>
        </itemizedlist>
      </para>
      <para>By using the &PRODNAME; API, you understand and agree to the following limitations and
          conditions:<itemizedlist spacing="compact">
          <listitem>
            <para>&PRODNAME; includes a Swift integration feature wherein Hadoop, MapReduce, or
              Apache Pig jobs can directly reference Cloud Files containers. </para>
          </listitem>
        </itemizedlist>
      </para>
      <para>The following resource limits apply: <itemizedlist spacing="compact">
          <listitem>
            <para>Up to 3 data nodes</para>
          </listitem>
          <listitem>
            <para>Up to 6 virtual CPUs</para>
          </listitem>
          <listitem>
            <para>Up to 23040 GB of RAM</para>
          </listitem>
          <listitem>
            <para>Up to 4500 GB of disk space</para>
          </listitem>
        </itemizedlist>
      </para>
    </section>
    <section xml:id="API_Contract_Changes-d1e122">
      <title>API contract changes</title>
      <para>The API contract is not locked and might change. If the contract changes, Rackspace will
        notify customers in release notes.</para>
    </section>
    <section xml:id="Pricing_SLA-d1e1362">
      <title>Pricing and service level</title>
      <para>&PRODNAME; is part of the Rackspace Cloud and your use through the API will be billed
        according to the pricing schedule at <link
          xlink:href="http://www.rackspace.com/cloud/big-data/pricing/"
          >http://www.rackspace.com/cloud/big-data/pricing/</link>.</para>
      <para>The Service Level Agreement (SLA) for Cloud Big Data is available at <link
          xlink:href="http://www.rackspace.com/cloud/legal/sla"
          >http://www.rackspace.com/cloud/legal/sla</link>.</para>
    </section>
    <section xml:id="Additional_Resources-d1e532">
      <title>Additional resources</title>
      <para>You can download the most current versions of the API-related documents from <link
          xlink:href="http://docs.rackspace.com/api/">docs.rackspace.com</link>. </para>
      <para>For information about Rackspace Cloud products, go to <link
          xlink:href="http://www.rackspace.com/cloud/"> www.rackspace.com/cloud</link>. This site
        also offers links to official Rackspace support channels, including knowledge base articles,
        forums, phone, chat, and email. </para>
      <para>Email all support questions to <email>cbdteam@rackspace.com</email>. </para>
      <para>For information about getting started using Cloud Big Data, refer to <citetitle>Getting
          Started with Rackspace Cloud Big Data</citetitle> at <link
          xlink:href="http://docs.rackspace.com/api/">docs.rackspace.com</link>.</para>
      <para>You can follow Rackspace updates and announcements via Twitter at <link
          xlink:href="http://www.twitter.com/rackspace">www.twitter.com/rackspace</link>. </para>
      <para>This API uses standard HTTP 1.1 response codes as documented at <link
          xlink:href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html"
          >www.w3.org/Protocols/rfc2616/rfc2616-sec10.html</link>. </para>
    </section>
  </chapter>
  <chapter xml:id="Concepts-d1e563">
    <title>Concepts</title>
    <?dbhtml stop-chunking?>
    <para>To use the Cloud Big Data API effectively, you should understand the terminology defined
      in the <xref linkend="glossary_1"/> at the end of the book.</para>
  </chapter>
  <chapter xml:id="General_API_Information-d1e633" xmlns:svg="http://www.w3.org/2000/svg"
    xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:html="http://www.w3.org/1999/xhtml">
    <title>General API information</title>
    <para>The &PRODNAME; API is implemented using a RESTful web service interface. &PRODNAME; shares
      a common token-based authentication system with other products in the Rackspace Cloud suite.
      This system enables seamless access between Rackspace products and services. </para>
    <note>
      <para> All requests to authenticate against and operate the service are performed using SSL
        over HTTP (HTTPS) on TCP port 443. </para>
    </note>
    <section xml:id="Authentication-d1e647">
      <title>Authentication</title>
      <para>Each REST request against the &PRODNAME; service requires the inclusion of a specific
        authorization token, supplied in the <code>X-Auth-Token</code> HTTP header. Customers obtain
        this token by first using the Rackspace Cloud Identity service and supplying a valid user
        name and API access key. </para>
      <para>To authenticate, you submit a <code>POST/v2.0/tokens</code> request, presenting valid
        Rackspace customer credentials in the message body to a Rackspace authentication endpoint. </para>
      <para><emphasis role="bold">1. GET YOUR CREDENTIALS</emphasis>
      </para>
      <para> You can use either of the following sets of credentials: <itemizedlist>
          <listitem>
            <para>Your user name and password</para>
          </listitem>
          <listitem>
            <para>Your user name and API key</para>
          </listitem>
        </itemizedlist>
      </para>
      <para>Your user name and password are the ones that you use to log in to the Rackspace Cloud
        Control Panel. After you are logged in, you can use the Rackspace Cloud Control Panel to
        obtain your API key. </para>
      <para> US and UK based accounts use the Cloud Control Panel at <link
          xlink:href="https://mycloud.rackspacecloud.com/">https://mycloud.rackspace.com/</link>. </para>
      <para>
        <emphasis role="bold">2. CHOOSE YOUR AUTHENTICATION ENDPOINT</emphasis>
      </para>
      <para>Use the authentication endpoint for the region in which your account is based. All
        accounts authenticate through <link
          xlink:href="https://identity.api.rackspacecloud.com/v2.0/tokens"
          >https://identity.api.rackspacecloud.com/v2.0/tokens</link>.</para>
      <para> </para>
      <para><emphasis role="bold">3. SEND YOUR CREDENTIALS TO YOUR AUTHENTICATION
          ENDPOINT</emphasis>
      </para>
      <para>If you know your credentials and your authentication endpoint, and you can issue a
          <code>POST /v2.0/tokens</code> request in an API call, you have all the basic information
        that you need to use the Rackspace Cloud Identity service. </para>
      <para> You can use <link xlink:href="http://curl.haxx.se/">cURL</link> to perform the
        authentication process in two steps: get a token, and send the token to a service.<orderedlist>
          <listitem>
            <para>Get an authentication token by providing your user name and either your API key or
              your password. Following are examples of both approaches:</para>
            <example>
              <title>User name and API key</title>
              <literallayout class="monospaced" language="bash">curl -X POST https://auth.api.rackspacecloud.com/v2.0/tokens -d 
'{ "auth":{ "RAX-KSKEY:apiKeyCredentials":{ "username":"yourUserName", "apiKey":"yourApiKey" } } }' -H "Content-type: application/json"</literallayout>
            </example>
            <example>
              <title>User name and password</title>
              <literallayout class="monospaced" language="bash">curl -X POST https://auth.api.rackspacecloud.com/v2.0/tokens -d
'{"auth":{"passwordCredentials":{"username":"yourUserName","password":"yourPassword"}}}' -H "Content-type: application/json"</literallayout>
            </example>
            <para>Successful authentication returns a token that you can use as evidence that your
              identity has already been authenticated. To use the token, pass it to other services
              as an <code>X-Auth-Token</code> header. </para>
            <para>Authentication also returns a service catalog, which lists the endpoints that you
              can use for Rackspace Cloud services. </para>
          </listitem>
          <listitem>
            <para>Use the authentication token to send a <command>GET</command> request to a service
              that you want to use. The following example shows passing an authentication token to
              the &PRODNAME; service by using the &PRODNAME; service catalog endpoint that was
              returned along with the token.</para>
            <example>
              <title>cURL get distros request: JSON</title>
              <programlisting language="bash">curl -i -X GET https://dfw.bigdata.api.rackspacecloud.com/v2/<emphasis role="bold">yourAccountID</emphasis>/distros -d  \
-H "X-Auth-Token: <emphasis role="bold">yourAuthToken</emphasis>" \
-H "Accept: application/json"\
-H "Content-type: application/json"</programlisting>
            </example>
          </listitem>
        </orderedlist>
      </para>
      <para>Authentication tokens are typically valid for 24 hours. Applications should be designed
        to re-authenticate after receiving a 401 (Unauthorized) response from a service endpoint. </para>
      <important>
        <para>If you are programmatically parsing an authentication response, be aware that service
          names are stable for the life of the particular service and can be used as keys. You
          should also be aware that a user's service catalog can include multiple uniquely named
          services that perform similar functions. In Cloud Identity 2.0, the service type attribute
          can be used as a key by which to recognize similar services. </para>
      </important>
    </section>
    <section xml:id="RBAC">
      <title>Role Based Access Control</title>
      <para>Role Based Access Control (RBAC) restricts access to the capabilities of Rackspace Cloud
        services, including the Cloud Big Data API, to authorized users only. RBAC enables Rackspace
        Cloud customers to specify which account users of their Cloud account have access to which
        Cloud Big Data API service capabilities, based on roles defined by Rackspace (see <xref
          linkend="RBAC_product_roles_table"/>). The permissions to perform certain operations in
        Cloud Big Data API – create, read, update, delete – are assigned to specific roles, and
        these roles can be assigned by the Cloud account admin user to account users of the account. </para>
      <section xml:id="Assigning-Roles-d1e001">
        <title>Assigning roles to account users</title>
        <para>The account owner (identity:user-admin) can create account users on the account and
          then assign roles to those users. The roles grant the account users specific permissions
          for accessing the capabilities of the Cloud Big Data service. Each account has only one
          account owner, and that role is assigned by default to any Rackspace Cloud account when
          the account is created.</para>
        <para>See the <citetitle>Cloud Identity Client Developer Guide</citetitle> for information
          about how to perform the following tasks:</para>
        <itemizedlist spacing="compact">
          <listitem>
            <para><link
              xlink:href="http://docs.rackspace.com/auth/api/v2.0/auth-client-devguide/content/POST_addUser__v2.0_users_User_Calls.html"
              >Create account users</link></para>
          </listitem>
          <listitem>
            <para><link
              xlink:href="http://docs.rackspace.com/auth/api/v2.0/auth-client-devguide/content/PUT_addUserRole__v2.0_users__userId__roles_OS-KSADM__roleid__Role_Calls.html"
              >Assign roles to account users</link></para>
          </listitem>
          <listitem>
            <para><link
              xlink:href="http://docs.rackspace.com/auth/api/v2.0/auth-client-devguide/content/DELETE_deleteUserRole__v2.0_users__userId__roles_OS-KSADM__roleid__Role_Calls.html"                            
              >Delete roles from account users</link></para>
          </listitem>
        </itemizedlist>
        <note>
          <para>The account admin user (identity:user-admin) role cannot hold any additional roles
            because it already has full access to all capabilities by default.</para>
        </note>
      </section>
      <section xml:id="RBAC_product_roles">
        <title>Roles available for Cloud Big Data </title>
        <para>Three roles (admin, creator, and observer) can be used to access the Cloud Big Data
          API specifically. The following table describes these roles and their permissions.</para>
        <table xml:id="RBAC_product_roles_table" rules="all">
          <caption>Cloud Big Data product roles and capabilities</caption>
          <col width="50%"/>
          <col width="50%"/>
          <thead>
            <tr>
              <th>Role name</th>
              <th>Role permissions</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>bigdata:admin</td>
              <td>This role provides Create, Read, Update, and Delete permissions in Cloud Big Data,
                where access is granted.</td>
            </tr>
            <tr>
              <td>bigdata:creator</td>
              <td>This role provides Create, Read and Update permissions in Cloud Big Data, where
                access is granted.</td>
            </tr>
            <tr>
              <td>bigdata:observer</td>
              <td>This role provides Read permission in Cloud Big Data, where access is
                granted.</td>
            </tr>
          </tbody>
        </table>
        <para>Additionally, two multiproduct roles apply to all products. Users with multiproduct
          roles inherit access to future products when those products become RBAC-enabled. The
          following table describes these roles and their permissions.</para>
        <table rules="all">
          <caption> Multiproduct (global) roles and permissions</caption>
          <col width="50%"/>
          <col width="50%"/>
          <thead>
            <tr>
              <th>Role name</th>
              <th>Role permissions</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>admin</td>
              <td>This role provides Create, Read, Update, and Delete permissions in all products,
                where access is granted.</td>
            </tr>
            <tr>
              <td>observer</td>
              <td>This role provides Read permission in all products, where access is granted.</td>
            </tr>
          </tbody>
        </table>
      </section>
      <section xml:id="RBAC-Resolving-Conflicts-d1e001" version="5.0">
        <title>Resolving conflicts between RBAC multiproduct vs. custom (product-specific)
          roles</title>
        <para>The account owner can set roles for both multiproduct and Cloud Big Data scope, and it
          is important to understand how any potential conflicts among these roles are resolved.
          When two roles appear to conflict, the role that provides the more extensive permissions
          takes precedence. Therefore, admin roles take precedence over observer and creator roles,
          because admin roles provide more permissions. </para>
        <para>The following table shows two examples of how potential conflicts between user roles
          in the Control Panel are resolved: </para>
        <para>
          <informaltable rules="all">
            <thead>
              <tr align="center">
                <td>Permission configuration</td>
                <td>View of permission in the Control Panel </td>
                <td>Can the user perform product admin functions in the Control Panel?</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>User is assigned the following roles: multiproduct <emphasis role="bold"
                    >observer</emphasis> and Cloud Big Data <emphasis role="bold"
                  >admin</emphasis></td>
                <td>Appears that the user has only the multiproduct <emphasis role="bold"
                    >observer</emphasis> role</td>
                <td>Yes, for Cloud Big Data only. The user has the <emphasis role="bold"
                    >observer</emphasis> role for the rest of the products.</td>
              </tr>
              <tr>
                <td>User is assigned the following roles: multiproduct <emphasis role="bold"
                    >admin</emphasis> and Cloud Big Data <emphasis role="bold"
                  >observer</emphasis></td>
                <td>Appears that the user has only the multiproduct <emphasis role="bold"
                    >admin</emphasis> role</td>
                <td>Yes, for all of the products. The Cloud Big Data <emphasis role="bold"
                    >observer</emphasis> role is ignored.</td>
              </tr>
            </tbody>
          </informaltable>
        </para>
      </section>
      <section xml:id="RBAC-Permissions-Cross-Ref-d1e001" version="5.0">
        <title>RBAC permissions cross-reference to Cloud Big Data API operations</title>
        <para>API operations for Cloud Big Data may or may not be available to all roles. To see
          which operations are permitted to invoke which calls, please review <link
            xlink:href="http://www.rackspace.com/knowledge_center/article/permissions-matrix-for-role-based-access-control-rbac"
            >the Knowledge Center article</link>.</para>
      </section>
    </section>
    <section xml:id="Service_Access_Endpoints-d1e753">
      <title>Service access endpoints</title>
      <para>The &PRODNAME; service is a regionalized service. The user of the service is therefore
        responsible for appropriate replication, caching, and overall maintenance of &PRODNAME; data
        across regional boundaries to other Cloud Servers.</para>
      <para>The endpoints to use for your Cloud Big Data API calls are summarized in the following
        table.</para>

        <para>To help you decide which regionalized endpoint to use, read the Knowledge Center article about special
          considerations for choosing a data center at <link
            xlink:href="http://www.rackspace.com/knowledge_center/article/about-regions"
            >About Regions</link>.</para>
      
      <para>
        <table rules="all">
          <caption>Regionalized service endpoints</caption>
          <thead>
            <tr align="center">
              <td colspan="2">Region</td>
              <td colspan="5">Endpoint</td>
            </tr>
          </thead>
          <tbody>
            <tr align="left">
              <td colspan="2">Chicago (ORD)</td>
              <td colspan="5"
                    ><code>https://ord.bigdata.api.rackspacecloud.com/v2/</code><parameter><replaceable>yourAccountID</replaceable></parameter>/
              </td>
            </tr>
            <tr align="left">
              <td colspan="2">Dallas/Ft. Worth (DFW)</td>
              <td colspan="5"
                    ><code>https://dfw.bigdata.api.rackspacecloud.com/v2/</code><parameter><replaceable>yourAccountID</replaceable></parameter>/
              </td>
            </tr>
            <tr align="left">
              <td colspan="2">London (LON)</td>
              <td colspan="5"
                    ><code>https://lon.bigdata.api.rackspacecloud.com/v2/</code><parameter><replaceable>yourAccountID</replaceable></parameter>/
              </td>
            </tr>
          </tbody>
        </table>
      </para>
      <para>Replace the <code><replaceable>yourAccountID</replaceable></code> placeholder with your
        actual account number, which is returned as part of the authentication service response,
        after the final '/' in the <code>publicURL</code> field. </para>
      <?rax-fo keep-with-next?>
    </section>
    <section xml:id="Request_Response_Types-d1e903">
      <title>Request and response types</title>
      <para>The &PRODNAME; API supports JSON data serialization formats. The request format is
        specified by using the <code>Content-Type</code> header and is required for operations that
        have a request body. The response format can be specified in requests either by using the
          <code>Accept</code> header or by adding <code>.json</code> extension to the request URI.
        Note that JSON is the default format for data serialization.</para>
      <table rules="all">
        <caption>Response formats</caption>
        <?dbfo keep-together="always"?>
        <thead>
          <tr align="center">
            <td>Format</td>
            <td>Accept header</td>
            <td>Query extension</td>
            <td>Default</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>JSON</td>
            <td>application/json</td>
            <td>.json</td>
            <td>Yes</td>
          </tr>
        </tbody>
      </table>
    </section>
    <section xml:id="volume_status">
      <title>Faults</title>
      <para>When an error occurs, the &PRODNAME; service returns a fault object that contains an
        HTTP error response code that denotes the type of error. In the body of the response, the
        system will return additional information about the fault.</para>
      <para>The following table lists possible fault types with their associated error codes and
        descriptions.</para>
      <informaltable rules="all">
        <thead>
          <tr align="center">
            <td colspan="2">Fault type</td>
            <td colspan="1">Associated error code</td>
            <td colspan="3">Description</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2"><code>badRequest</code></td>
            <td colspan="1">400</td>
            <td colspan="3">The user-provided request contained an error.</td>
          </tr>
          <tr>
            <td colspan="2"><code>unauthorized</code></td>
            <td colspan="1">401</td>
            <td colspan="3">The supplied token is not authorized to access the resources. The token
              is either expired or invalid.</td>
          </tr>
          <tr>
            <td colspan="2"><code>forbidden</code></td>
            <td colspan="1">403</td>
            <td colspan="3">Access to the requested resource was denied.</td>
          </tr>
          <tr>
            <td colspan="2"><code>itemNotFound</code></td>
            <td colspan="1">404</td>
            <td colspan="3">The back-end services did not find anything matching the request
              URI.</td>
          </tr>
          <tr>
            <td colspan="2"><code>conflictingRequest</code></td>
            <td colspan="1">409</td>
            <td colspan="3">The requested resource cannot currently be operated on.</td>
          </tr>
          <tr>
            <td colspan="2"><code>overLimit</code></td>
            <td colspan="1">413</td>
            <td colspan="3">The resource quota was exceeded.</td>
          </tr>
          <tr>
            <td colspan="2"><code>lavaFault</code></td>
            <td colspan="1">500</td>
            <td colspan="3">An unknown exception occurred.</td>
          </tr>
          <tr>
            <td colspan="2"><code>serviceUnavailable</code></td>
            <td colspan="1">503</td>
            <td colspan="3">The service is currently unavailable.</td>
          </tr>
        </tbody>
      </informaltable>
    </section>
    <section xml:id="Limits-d1e1208">
      <title>Limits</title>
      <para>All accounts, by default, have a preconfigured set of thresholds (or limits) to manage
        capacity and prevent abuse of the system. The system recognizes <firstterm>rate
          limits</firstterm> and <firstterm>absolute limits</firstterm>. Rate limits are thresholds
        that are reset after a certain amount of time passes. Absolute limits are fixed. </para>
      <section xml:id="Rate_Limits-d1e1222">
        <title>Rate limits</title>
        <para>Rate limits are specified in both a human-readable wildcard URI and a
          machine-processable regular expression. The regular expression boundary matcher
            '<code>^</code>' takes effect after the root URI path. For example, the regular
          expression <code>^/v2/clusters</code> would match the bold portion of the following URI:
            https://dfw.bigdata.api.rackspacecloud.com<emphasis role="bold">/v2/clusters</emphasis>. </para>
        <para>The following table specifies the default rate limits for all &GET;, , &PUT;, and
          &DELETE; &POST;API operations for clusters.</para>
        <table rules="all">
          <caption>Default rate limits</caption>
          <thead>
            <tr align="center">
              <td colspan="1">Verb</td>
              <td colspan="2">URI</td>
              <td colspan="2">Regular expression</td>
              <td colspan="1">Default</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="1">&GET; changes-since</td>
              <td colspan="2">*/clusters/*</td>
              <td colspan="2">^/vd+.d+/clusters.*</td>
              <td colspan="1">3 per minute</td>
            </tr>
            <tr>
              <td colspan="1">&POST;</td>
              <td colspan="2">*/clusters/*</td>
              <td colspan="2">^/vd+.d+/clusters.*</td>
              <td colspan="1">2 per minute</td>
            </tr>
            <tr>
              <td colspan="1">&POST; clusters</td>
              <td colspan="2">*/clusters/*</td>
              <td colspan="2">^/vd+.d+/clusters.*</td>
              <td colspan="1">50 per day</td>
            </tr>
            <tr>
              <td colspan="1">&PUT;</td>
              <td colspan="2">*/clusters/*</td>
              <td colspan="2">^/vd+.d+/clusters.*</td>
              <td colspan="1">2 per minute</td>
            </tr>
            <tr>
              <td colspan="1">&DELETE;</td>
              <td colspan="2">*/clusters/*</td>
              <td colspan="2">^/vd+.d+/clusters.*</td>
              <td colspan="1">5 per minute</td>
            </tr>
          </tbody>
        </table>
        <para>Rate limits are applied in order relative to the verb, going from least to most
          specific. For example, although the threshold for issuing a &POST; request to
            <code>/v2/*</code> is 2 per minute, you cannot issue a &POST; request to
            <code>/v2/*</code> more than 50 times within a single day. </para>
        <para>If you exceed the thresholds established for your account, a <errorcode>413
            (OverLimit)</errorcode> HTTP response is returned with a <code>Retry-After</code> header
          to notify the client when it can attempt to try again. </para>
      </section>
      <section xml:id="Absolute_Limits-d1e1397">
        <title>Absolute limits</title>
        <para>The following table provides the default values for the absolute limits.</para>
        <table rules="all">
          <caption>Absolute limits</caption>
          <thead>
            <tr align="center">
              <td colspan="1">Name</td>
              <td colspan="3">Description</td>
              <td colspan="1">Limit - default values</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="1">Node count</td>
              <td colspan="3">Maximum number of allowed data nodes</td>
              <td colspan="1">3</td>
            </tr>
            <tr>
              <td colspan="1">Disk</td>
              <td colspan="3">Maximum disk capacity across all data nodes, in gigabytes (GB) </td>
              <td colspan="1">4500</td>
            </tr>
            <tr>
              <td colspan="1">RAM</td>
              <td colspan="3">Maximum RAM across all data nodes, in gigabytes (GB)</td>
              <td colspan="1">23040</td>
            </tr>
            <tr>
              <td colspan="1">VCPUs</td>
              <td colspan="3">Maximum virtual CPUs across all data nodes</td>
              <td colspan="1">6</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>
    <section xml:id="datetimeformat">
      <title>Date and time format</title>
      <para>For the display and consumption of date and time values, the &PRODNAME; service uses a
        date format that complies with ISO 8601. </para>
      <para>The system time is expressed as UTC.</para>
      <example>
        <title>&PRODNAME; service date and time format</title>
        <programlisting>yyyy-MM-dd'T'HH:mm:ss.SSSZ</programlisting>
        <para>For example, May 19, 2013 at 8:07:08 a.m., UTC-5 would have the following format: </para>
        <para><code>2013-05-19T08:07:08 -0500</code>
        </para>
        <para>The following table describes the date and time format codes. </para>
      </example>
      <table rules="all">
        <caption>Explanation of date and time format codes</caption>
        <thead>
          <tr>
            <td>Code</td>
            <td>Description</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>yyyy</td>
            <td>Four-digit year</td>
          </tr>
          <tr>
            <td>MM</td>
            <td>Two-digit month</td>
          </tr>
          <tr>
            <td>dd</td>
            <td>Two-digit day of the month</td>
          </tr>
          <tr>
            <td>T</td>
            <td>Separator of the date and time</td>
          </tr>
          <tr>
            <td>HH</td>
            <td>Two-digit hour of the day (00-23)</td>
          </tr>
          <tr>
            <td>mm</td>
            <td>Two-digit minutes of the hour</td>
          </tr>
          <tr>
            <td>ss</td>
            <td>Two-digit seconds of the minute</td>
          </tr>
          <tr>
            <td>SSS</td>
            <td>Three-digit milliseconds of the second</td>
          </tr>
          <tr>
            <td>Z</td>
            <td>RFC 822 time zone</td>
          </tr>
        </tbody>
      </table>
    </section>
    
    <section xml:id="pagination">
      <title>Pagination</title>
      <para>Pagination provides the ability to limit the size of the returned data in the response
        body as well as retrieve a specified subset of a large data set. Pagination has two key
        concepts: <emphasis>limit</emphasis> and <emphasis>marker</emphasis>. </para>
      <para>
        <itemizedlist>
          <listitem>
            <para><code>limit</code> is the restriction on the maximum number of items for that type
              that can be returned. </para>
          </listitem>
          <listitem>
            <para><code>marker</code> is the ID of the last item in the previous list returned. </para>
            <para>The ID is the respective ID for the last cluster, node, or flavor. For example, a
              query could request the next 10 nodes after the node “xyz” as follows:
                <code>?limit=10&amp;marker=xyz</code>. Items displayed are sorted by ID. </para>
          </listitem>
        </itemizedlist>
      </para>
      <para>Pagination applies only to the operations listed in the following table: </para>
      <informaltable rules="all">
        <thead>
          <tr align="center">
            <td colspan="1">Verb</td>
            <td colspan="2">URI</td>
            <td colspan="3">Description</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="1">&GET;</td>
            <td colspan="2">/v2/{tenant_id}/clusters </td>
            <td colspan="3">Lists all clusters for your account.</td>
          </tr>
          <tr>
            <td colspan="1">&GET;</td>
            <td colspan="2">/v2/{tenant_id}/clusters/{clusterId}/nodes </td>
            <td colspan="3">Lists all nodes for the specified cluster.</td>
          </tr>
          <tr>
            <td colspan="1">&GET;</td>
            <td colspan="2">/v2/{tenant_id}/flavors</td>
            <td colspan="3">Lists all available flavors, including the drive size and the amount of
              RAM.</td>
          </tr>
        </tbody>
      </informaltable>
      <para>The default paging limit for all calls is 25 with a maximum of 200. Requests for more
        than 200 result in a 400 error.</para>
      <para>See the following example of the operation to list paged nodes.</para>
      <example>
        <title>List nodes paged request: JSON</title>
        <programlisting language="bash"><xi:include href="../resources/samples/cbd_listNodes_pagination_request-v2.json" parse="text"/></programlisting>
      </example>
      <para>Notice that the preceding paged request example sets the limit to 2
          (<code>?limit=2</code>), so the response that follows shows 2 nodes:</para>
      <example>
        <title>List nodes paged response: JSON</title>
        <programlisting language="json"><xi:include href="../resources/samples/cbd_listNodes_pagination_response-v2.json" parse="text"/> </programlisting>
      </example>
    </section>
    <section xml:id="dataNodeInstances-d1e01">
      <title>Data node instances</title>
      <para>Cloud Big Data offers the data node instances described in the following table.</para>
      <table rules="all">
        <caption>Data node instances</caption>
        <thead>
          <tr>
            <th>Flavor ID</th>
            <th>Name</th>
            <th>vCPU</th>
            <th>RAM</th>
            <th>Disk</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>hadoop1-7</td>
            <td>Small Hadoop Instance</td>
            <td>2</td>
            <td>7.5 GB</td>
            <td>1.25 TB</td>
          </tr>
          <tr>
            <td>hadoop1-15</td>
            <td>Medium Hadoop Instance</td>
            <td>4</td>
            <td>15 GB</td>
            <td>2.5 TB</td>
          </tr>
          <tr>
            <td>hadoop1-30</td>
            <td>Large Hadoop Instance</td>
            <td>8</td>
            <td>30 GB</td>
            <td>5 TB</td>
          </tr>
          <tr>
            <td>hadoop1-60</td>
            <td>XLarge Hadoop Instance</td>
            <td>16</td>
            <td>60 GB</td>
            <td>10 TB</td>
          </tr>
        </tbody>
      </table>
      <para>For more information about data node instances, see <link
          xlink:href="http://www.rackspace.com/knowledge_center/article/cloud-big-data-platform-provisioning-and-pricing"
          >http://www.rackspace.com/knowledge_center/article/cloud-big-data-platform-provisioning-and-pricing</link>.
      </para>
    </section>
    <section xml:id="cluster_status">
      <title>Cluster status</title>
      <para><?rax-fo keep-with-next?>When you send an API request to create, list, or delete a
        cluster or clusters, the following cluster status values might be returned:</para>
      <itemizedlist spacing="compact">
        <listitem>
          <para>BUILDING &ndash; The cluster is being provisioned.</para>
        </listitem>
        <listitem>
          <para>CONFIGURING &ndash; The cluster is being configured.</para>
        </listitem>
        <listitem>
          <para>ACTIVE &ndash; The cluster is online and available to for use.</para>
        </listitem>
        <listitem>
          <para>UPDATING &ndash; The cluster is being updated, either through a resize operation or
            another update operation.</para>
        </listitem>
        <listitem>
          <para>ERROR &ndash; The cluster failed to start up.</para>
        </listitem>
        <listitem>
          <para>DELETING &ndash; The cluster is being deleted.</para>
        </listitem>
        <listitem>
          <para>DELETED &ndash; The cluster is deleted.</para>
        </listitem>
      </itemizedlist>
      <para>The following figure shows the cluster states and the operations that are valid for each
        one. <figure>
          <title>Cluster states with valid operations</title>
          <mediaobject>
            <imageobject>
              <imagedata format="svg" align="center" scale="50" fileref="figures/cluster-states.png"
              />
            </imageobject>
          </mediaobject>
        </figure>
      </para>
    </section>
    <section xml:id="node_status">
      <title>Node status</title>
      <para><?rax-fo keep-with-next?>When you send an API request to list or get details about a
        node or nodes, the following node status values might be returned:</para>
      <itemizedlist spacing="compact">
        <listitem>
          <para>BUILDING &ndash; Cloud Big Data is waiting for a nova resource to become
            available.</para>
        </listitem>
        <listitem>
          <para>CONFIGURING &ndash; The server resource was acquired from nova and is being
            configured for cluster.</para>
        </listitem>
        <listitem>
          <para>ACTIVE &ndash; The node is provisioned and part of a cluster.</para>
        </listitem>
        <listitem>
          <para>ERROR &ndash; The provisioning failed for the node.</para>
        </listitem>
        <listitem>
          <para>DELETING &ndash; A delete was requested but is not yet completed.</para>
        </listitem>
        <listitem>
          <para>DELETED &ndash; The node has been deleted, and the nova resource has been
            freed.</para>
        </listitem>
        <listitem>
          <para>DEACTIVATING &ndash; The node is preparing to be removed from the cluster.</para>
        </listitem>
      </itemizedlist>
    </section>
  </chapter>
  <chapter xml:id="API_Operations_dle2000" xmlns="http://docbook.org/ns/docbook"
    role="api-reference">
    <title>API operations</title>
    <para>The chapter describes each of the API operations provided by the Cloud Big Data service. </para>
    <section xml:id="distroOperations">
      <title>Distros</title>
      <para>Distros provide a list of supported distributions and their corresponding versions, as
        well as a list of supported services and components per distribution.</para>
      <para>The following table shows the Cloud Big Data API operations that are available for
        distros. These operations are described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#distros"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#distro"/>
      </wadl:resources>
    </section>
    <section xml:id="stackOperations">
      <title>Stacks</title>
      <para>Stacks are high-level building blocks of software that compose a Big Data architecture.
        Stacks are comprised of services, which in turn are comprised of components. A stack is
        specific to a distribution due to the differences in services that are supported across
        distributions.</para>
      <para>The following table shows the Cloud Big Data API operations that are available for
        stacks. These operations are described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#stacks"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#stack"/>
      </wadl:resources>
    </section>
    <section xml:id="clusterOperations">
      <title>Clusters</title>
      <para>Clusters are a group of servers (nodes). In Cloud Big Data, the servers are
        virtual.</para>
      <para>The following table shows the Cloud Big Data API operations that are available for
        clusters. These operations are described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#clusters"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#cluster"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#action"/>
      </wadl:resources>
    </section>
    <section xml:id="nodeOperations">
      <title>Nodes</title>
      <para>In a network, a node (or server) is a connection point - either a redistribution point
        or an end point for data transmissions. In general, a node has programmed or engineered
        capability to recognize and process or forward transmissions to other nodes. A node is a
        member of a cluster.</para>
      <para>The following table shows the Cloud Big Data API operations that are available for
        nodes. These operations are described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#nodes"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#node"/>
      </wadl:resources>
    </section>
    <section xml:id="flavorOperations">
      <title>Flavors</title>
      <para>A flavor is an available configuration for Cloud Big Data. Each flavor has a unique
        combination of memory capacity and priority for CPU time.</para>
      <para>The following table shows the Cloud Big Data API operations that are available for
        flavors. These operations are described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#flavors"/>
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#flavor"/>
      </wadl:resources>
    </section>
    <section xml:id="limitsOperations">
      <title>Resource limits</title>
      <para>Resource limits include items such as remaining node count, available RAM, and remaining
        disk space for the user.</para>
      <para>The following table shows the Cloud Big Data API operation that is available for
        resource limits. This operation is described in this section.</para>
      <para/>
      <wadl:resources xmlns:wadl="http://wadl.dev.java.net/2009/02">
        <wadl:resource href="../../src/wadl/cbd-devguide-2.wadl#limits"/>
      </wadl:resources>
    </section>
  </chapter>
  <glossary xml:id="glossary_1">
    <title>Glossary</title>
    <glossentry>
      <glossterm>Cluster</glossterm>
      <glossdef>
        <para> A cluster is a group of servers (nodes). In Cloud Big Data, the servers are
          virtual.</para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Distro</glossterm>
      <glossdef>
        <para>Distros provide a list of supported distributions and their corresponding versions, as
          well as a list of supported services and components per distribution.</para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Flavor</glossterm>
      <glossdef>
        <para>A flavor is an available configuration for Cloud Big Data. Each flavor has a unique
          combination of memory capacity and priority for CPU time.</para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="HDFS-d1e020">
      <glossterm>HDFS</glossterm>
      <glossdef>
        <para>The Apache Hadoop Distributed File System. This is the default file system used in
          &PRODNAME;.</para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="MapReduce-d1e019">
      <glossterm>MapReduce</glossterm>
      <glossdef>
        <para>A framework for performing calculations on the data in the distributed file system.
          Map tasks run in parallel with each other. Reduce tasks also run in parallel with each
          other. </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="node-d1e018">
      <glossterm>Node</glossterm>
      <glossdef>
        <para>In a network, a node (or server) is a connection point, either a redistribution point
          or an end point for data transmissions. In general, a node has programmed or engineered
          capability to recognize and process or forward transmissions to other nodes. A node is a
          member of a cluster.</para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Resource limits</glossterm>
      <glossdef>
        <para>Resource limits include items such as remaining node count, available RAM, and
          remaining disk space for the user.</para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="SCPServerProxy-d1e018">
      <glossterm>SCP server proxy</glossterm>
      <glossdef>
        <para>An SCP service that runs on your Hadoop cluster and distributes your files across the
          cluster. </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="ServiceCatalog-d1e018">
      <glossterm>Service catalog</glossterm>
      <glossdef>
        <para>Your service catalog is the list of services available to you, as returned along with
          your authentication token and an expiration date for that token. All the services in your
          service catalog should recognize your token as valid until it expires.</para>
        <para>The catalog listing for each service provides at least one endpoint URL for that
          service. Other information, such as regions and versions and tenants, is provided if it is
          relevant to your access to this service.</para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Stack</glossterm>
      <glossdef>
        <para>Stacks are high-level building blocks of software that compose a Big Data
          architecture. Stacks are comprised of services, which in turn are comprised of components.
          A stack is specific to a distribution due to the differences in services that are
          supported across distributions.</para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="tenant">
      <glossterm>Tenant</glossterm>
      <glossdef>
        <para>A container used to group or isolate resources or identity objects. Depending on the
          service operator, a tenant could map to a customer, account, organization, or project.
        </para>
      </glossdef>
    </glossentry>
  </glossary>
</book>
